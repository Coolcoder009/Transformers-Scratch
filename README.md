# üî§ English‚ÄìTamil Transformer from Scratch (PyTorch)

This project demonstrates a **Transformer-based neural machine translation** model built **completely from scratch** using **PyTorch**. The goal was to translate English to Tamil using a small dataset and limited compute resources.

---

## üìå Overview

- ‚úÖ Implemented Transformer architecture from scratch (no high-level libs like `torch.nn.Transformer`)
- üó£Ô∏è Trained on **200,000 English‚ÄìTamil sentence pairs**
- üèãÔ∏è‚Äç‚ôÇÔ∏è Trained for **20 epochs** due to compute limitations
- üîÑ Translation supported via:
  - **Greedy decoding**
  - **Beam search decoding**
- üìâ Accuracy is low due to limited training, but the model shows learning ability
- üöÄ When trained for more epochs, performance improves significantly

---

## üß† Model Architecture

- Encoder‚ÄìDecoder Transformer
- Positional Encoding
- Masked Multi-Head Attention
- Layer Normalization
- Cross-Attention between Encoder and Decoder
- Beam Search and Greedy Decoding

---

## ‚öôÔ∏è Training Details

| Item              | Description                    |
|-------------------|--------------------------------|
| Dataset           | 200,000 English‚ÄìTamil pairs    |
| Epochs            | 20                             |
| Batch Size        | 32                             |
| Optimizer         | Adam with warmup scheduler     |
| Loss              | Cross-Entropy with masking     |
| Beam Width        | 3                              |

---

## üì• Example Translations

| English                     | Tamil (Greedy)                              | Tamil (Beam Search)                 |
|-----------------------------|---------------------------------------------|-------------------------------------|
| It's not your fault         | ‡Æâ‡Æ©‡Øç ‡ÆÆ‡ØÅ‡Æ¥‡ØÅ‡Æµ‡Æ§‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æ≤‡Øç‡Æ≤‡Øà                         | ‡Æâ‡Æ©‡Øç ‡ÆÆ‡ØÅ‡Æ¥‡ØÅ‡Æµ‡Æ§‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æ≤‡Øç‡Æ≤‡Øà                 |
| How are you brother?        | ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æï‡Ææ‡Æ§‡Æ≤‡Æø‡Æï‡Øç‡Æï‡ØÅ ‡Æé‡Æ©‡Øç‡Æ© ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡ØÅ ‡Æï‡Øä‡Æ£‡Øç‡Æü‡Ææ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç?     | ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æé‡Æ©‡Øç‡Æ©?             |

> ‚ö†Ô∏è These translations are **not accurate yet** due to limited training. With more epochs, the model's performance improves.

---

## üõ†Ô∏è Run Locally

```bash
# Clone the repo
https://github.com/Coolcoder009/Transformers-Scratch.git
cd Transformers-Scratch

# Environment variable creation
python -m venv venv

# Activate 
venv/scripts/activate

# Train the model
python train.py
